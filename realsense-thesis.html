<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RealSense Road Scanner: システム技術解説書</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!-- Add Mermaid for Gen2 Flowchart -->
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: false });
        window.mermaid = mermaid;
        // Render Mermaid after all tabs are visible, then restore tab visibility
        document.addEventListener('DOMContentLoaded', async function () {
            // Temporarily show all tab content for Mermaid rendering
            var allTabs = document.querySelectorAll('.tab-content');
            allTabs.forEach(function (tab) { tab.style.display = 'block'; });
            // Wait for Mermaid to render
            await mermaid.run();
            // Restore proper tab visibility (only gen1 visible)
            allTabs.forEach(function (tab) { tab.style.display = 'none'; });
            document.getElementById('gen1').style.display = 'block';
        });
    </script>
    <style>
        body {
            font-family: "Yu Mincho", "Hiragino Mincho ProN", serif;
            background-color: #f9f9f9;
            margin: 0;
            padding: 0;
        }

        .content-wrapper {
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        .back-link {
            display: inline-block;
            margin-bottom: 20px;
            color: #0056b3;
            text-decoration: none;
            font-weight: 600;
        }

        .back-link:hover {
            text-decoration: underline;
        }

        h1 {
            text-align: center;
            font-size: 2.5em;
            margin-bottom: 10px;
            border-bottom: 2px solid #333;
            padding-bottom: 20px;
            word-wrap: break-word;
        }

        .author {
            text-align: center;
            margin-bottom: 50px;
            font-size: 1.2em;
        }

        h2 {
            font-size: 1.8em;
            margin-top: 40px;
            border-left: 5px solid #0056b3;
            padding-left: 15px;
            background-color: #eef;
            padding-top: 5px;
            padding-bottom: 5px;
            word-wrap: break-word;
        }

        h3 {
            font-size: 1.4em;
            margin-top: 30px;
            border-bottom: 1px solid #ccc;
            padding-bottom: 5px;
            word-wrap: break-word;
        }

        h4 {
            font-size: 1.2em;
            margin-top: 25px;
            word-wrap: break-word;
        }

        p {
            margin-bottom: 1.5em;
            text-align: justify;
            line-height: 1.8;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }

        .abstract {
            font-style: italic;
            margin: 40px 0;
            padding: 20px;
            background-color: #fff;
            border: 1px solid #ddd;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05);
        }

        .equation {
            text-align: center;
            margin: 20px 0;
            font-family: "Times New Roman", serif;
            overflow-x: auto;
            overflow-y: hidden;
        }

        code {
            font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
            background-color: #f0f0f0;
            padding: 2px 5px;
            border-radius: 3px;
            word-wrap: break-word;
        }

        ul,
        ol {
            margin-bottom: 20px;
            padding-left: 35px;
            line-height: 1.9;
        }

        li {
            margin-bottom: 10px;
            word-wrap: break-word;
        }

        section {
            background: white;
            padding: 30px;
            margin-bottom: 30px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05);
        }

        strong {
            font-weight: 600;
        }

        footer {
            text-align: center;
            margin-top: 40px;
            padding: 20px;
            color: #666;
        }

        /* Tab Styles */
        .tabs {
            display: flex;
            justify-content: center;
            margin-bottom: 30px;
            border-bottom: 1px solid #ccc;
        }

        .tab-button {
            background: #fff;
            border: 1px solid #ccc;
            border-bottom: none;
            padding: 10px 20px;
            margin: 0 5px;
            cursor: pointer;
            font-family: inherit;
            font-size: 1.1em;
            border-radius: 5px 5px 0 0;
            transition: background 0.3s;
        }

        .tab-button:hover {
            background: #eef;
        }

        .tab-button.active {
            background: #0056b3;
            color: white;
            border-color: #0056b3;
        }

        .tab-content {
            display: none;
            animation: fadeIn 0.5s ease;
        }

        .tab-content.active {
            display: block;
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
            }

            to {
                opacity: 1;
            }
        }

        /* Mermaid Styles */
        .mermaid {
            text-align: center;
            margin: 20px 0;
        }

        /* Table Styles from draft */
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }

        th,
        td {
            border: 1px solid #ddd;
            padding: 8px 12px;
            text-align: left;
        }

        th {
            background-color: #f2f2f2;
        }

        /* Note Style from Draft */
        .note {
            background-color: #f1f8ff;
            border-left: 4px solid #3498db;
            padding: 10px 15px;
            margin: 15px 0;
            color: #2c3e50;
            font-size: 0.9em;
        }

        /* Math Block from Draft */
        .math-block {
            background: #fdfdfd;
            border: 1px solid #eee;
            padding: 15px;
            border-radius: 5px;
            text-align: center;
            margin: 10px 0;
        }

        /* スマホ対応 */
        @media (max-width: 768px) {
            .content-wrapper {
                padding: 20px 10px;
            }

            h1 {
                font-size: 1.8em;
                padding-bottom: 15px;
            }

            h2 {
                font-size: 1.4em;
                padding-left: 10px;
            }

            h3 {
                font-size: 1.2em;
            }

            h4 {
                font-size: 1.1em;
            }

            section {
                padding: 15px;
            }

            .equation {
                font-size: 0.9em;
            }

            ul,
            ol {
                padding-left: 20px;
            }
        }

        @media (max-width: 480px) {
            h1 {
                font-size: 1.5em;
            }

            h2 {
                font-size: 1.2em;
            }

            h3 {
                font-size: 1.1em;
            }

            .equation {
                font-size: 0.8em;
            }
        }
    </style>
    <script>
        function openTab(tabName, btn) {
            var i, tabcontent, tablinks;
            tabcontent = document.getElementsByClassName("tab-content");
            for (i = 0; i < tabcontent.length; i++) {
                tabcontent[i].style.display = "none";
                tabcontent[i].classList.remove("active");
            }
            tablinks = document.getElementsByClassName("tab-button");
            for (i = 0; i < tablinks.length; i++) {
                tablinks[i].classList.remove("active");
            }
            document.getElementById(tabName).style.display = "block";
            document.getElementById(tabName).classList.add("active");
            btn.classList.add("active");
        }
    </script>
</head>

<body>
    <div class="content-wrapper">
        <a href="index.html" class="back-link">← トップページに戻る</a>

        <h1>RealSense Road Scanner システム技術解説書</h1>
        <div class="author"><strong>Technical Anatomoy (Gen 1 / Gen 2)</strong></div>

        <div class="tabs">
            <button class="tab-button active" onclick="openTab('gen1', this)">Gen 1 (Adaptive Baseline)</button>
            <button class="tab-button" onclick="openTab('gen2', this)">Gen 2 (SVD Plane Fitting)</button>
        </div>

        <div id="gen1" class="tab-content active">
            <!-- Gen1 Content Start -->
            <section>
                <h2>1. 概要 (Abstract)</h2>
                <p>
                    本システム「RealSense Road Scanner」は，Intel RealSense D435i深度カメラを用いた路面性状のリアルタイム監視システムである．
                    車両前方の路面状況を深度センサでスキャンし，突起や障害物を高精度に検出する．
                    本稿では，深度データ処理による障害物検知アルゴリズムの数理モデルおよび実装詳細について記述する．
                </p>
            </section>

            <section>
                <h2>2. センシングアルゴリズム (Detection Algorithm)</h2>
                <p>
                    路面の微細な変化（2cm程度の突起）を検出するため，深度データに対して高度なフィルタリングと適応的なベースライン推定を行っている．
                </p>

                <h3>2.1 深度データの取得と前処理</h3>
                <p>
                    RealSense D435iから取得される生の深度フレーム \( D_{raw}(x, y, t) \) はノイズを含むため，以下のフィルタ処理パイプライン \( \mathcal{F} \)
                    を適用する．
                </p>
                <div class="equation">
                    $$ D_{filtered} =
                    \mathcal{F}_{HoleFilling}(\mathcal{F}_{Temporal}(\mathcal{F}_{Spatial}(\mathcal{F}_{Decimation}(D_{raw}))))
                    $$
                </div>

                <h4>2.1.1 Decimation Filter (\( \mathcal{F}_{Decimation} \))</h4>
                <p>
                    解像度を削減し，計算負荷を軽減すると同時に平滑化を行う．間引き係数 \( s \times s \) のブロック内の深度値をメディアンフィルタまたは平均化によって単一の代表値に集約する．
                </p>
                <div class="equation">
                    $$ D_{dec}(x', y') = \text{Median} \left\{ D_{raw}(sx' + i, sy' + j) \mid 0 \leq i, j < s \right\}
                        $$ </div>

                        <h4>2.1.2 Spatial Filter (\( \mathcal{F}_{Spatial} \))</h4>
                        <p>
                            空間的なエッジ保存平滑化フィルタ（バイラテラルフィルタ）を適用する．
                        </p>
                        <div class="equation">
                            $$ D_{spatial}(x, y) = \frac{1}{W(x,y)} \sum_{(i,j) \in \Omega} D(i,j) \cdot \exp\left(
                            -\frac{(x-i)^2 + (y-j)^2}{2\sigma_s^2} \right) \cdot \exp\left( -\frac{(D(x,y) -
                            D(i,j))^2}{2\sigma_r^2} \right) $$
                        </div>

                        <h4>2.1.3 Temporal Filter (\( \mathcal{F}_{Temporal} \))</h4>
                        <p>
                            時間軸方向の平滑化を行い，フリッカーを抑制する（EMA）．
                        </p>
                        <div class="equation">
                            $$ D_{temp}(x, y, t) = \alpha_{temp} \cdot D(x, y, t) + (1 - \alpha_{temp}) \cdot
                            D_{temp}(x, y, t-1) $$
                        </div>

                        <h4>2.1.4 Hole Filling Filter (\( \mathcal{F}_{HoleFilling} \))</h4>
                        <p>
                            欠損領域を周囲の有効な深度値から補間する．
                        </p>
                        <div class="equation">
                            $$ D_{filled}(x, y) = \frac{\sum_{(i,j) \in \mathcal{N}(x,y), D(i,j) \neq 0} w(i,j) \cdot
                            D(i,j)}{\sum_{(i,j) \in \mathcal{N}(x,y), D(i,j) \neq 0} w(i,j)} $$
                        </div>

                        <h3>2.2 路面ベースラインの適応的推定 (EMA)</h3>
                        <p>
                            路面は常に平坦ではなく，勾配やうねりが存在する．
                            関心領域（ROI）内の中央値 \( d_t \) を用いて，ベースライン \( B_t \) を更新する．
                        </p>
                        <div class="equation">
                            $$ d_t = \text{Percentile}(D_{filtered}(x, y, t) \mid_{(x,y) \in ROI}, 50) $$
                            $$ B_t = \alpha \cdot d_t + (1 - \alpha) \cdot B_{t-1} $$
                        </div>

                        <h3>2.3 障害物検知判定</h3>
                        <p>
                            現在の深度 \( d_t \) が，推定されたベースライン \( B_t \) よりも有意に手前（カメラに近い）にある場合，障害物と判定する．
                        </p>
                        <div class="equation">
                            $$ C_{detect}(t) = \begin{cases}
                            1 (True) & \text{if } d_t < B_t - h_{thresh} \\ 0 (False) & \text{otherwise} \end{cases} $$
                                </div>
            </section>

            <section>
                <h2>3. 制御と遅延補償 (SYSTEM Control & Delay Compensation)</h2>
                <p>
                    カメラによる検知時刻 \( t_{detect} \) と，実際の到達時刻 \( t_{target} \) の時間差を「遅延バッファ」で管理する．
                </p>

                <h3>3.1 遅延バッファリングモデル</h3>
                <div class="equation">
                    $$ t_{target} = t_{now} + T_{delay} $$
                </div>

                <h3>3.2 サーボ角度制御</h3>
                <div class="equation">
                    $$ \theta_{target}(t) = \theta_{base} + \Delta \theta(t) $$
                </div>

                <h3>3.3 遅延学習（Delay Learning Mode）</h3>
                <p>
                    ジャイロセンサ検知時刻 \( t_{phys} \) とカメラ検知時刻 \( t_{cam} \) から遅延時間 \( T_{delay} \) を自己学習する．
                </p>
                <div class="equation">
                    $$ T_{delay}^{(new)} = T_{delay}^{(old)} + \beta \cdot (\Delta t_{measured} - T_{delay}^{(old)}) $$
                </div>
            </section>

            <section>
                <h2>4. システムアーキテクチャ (Implementation Details)</h2>
                <p>
                    本システムはPython (Backend) と JavaScript (Frontend) で構成され，WebSocket (Eel) を介して通信を行う．
                </p>
                <ul>
                    <li><strong>Main Loop (Python):</strong> センサーフュージョンと制御の主ループ．</li>
                    <li><strong>RealSense Manager:</strong> 深度フレームの取得・処理．</li>
                    <li><strong>Delay Buffer:</strong> 時間管理されたコマンドの発火制御．</li>
                    <li><strong>Frontend (Chart.js):</strong> リアルタイム可視化．</li>
                </ul>

                <h2>5. Python実装詳細と使用ライブラリ</h2>
                <p>
                    主要ライブラリ: <code>pyrealsense2</code>, <code>numpy</code>, <code>opencv-python</code>.
                </p>
                <ul>
                    <li><strong>rs.pipeline():</strong> データストリーム管理．</li>
                    <li><strong>rs.spatial_filter(), rs.temporal_filter():</strong> フィルタ処理の実装．</li>
                    <li><strong>np.median(), np.percentile():</strong> 統計量計算によるロバストな検知．</li>
                </ul>

                <h3>5.4 実装例: ROIベースの障害物検知</h3>
                <div class="equation">
                    <code style="display: block; text-align: left; white-space: pre; font-size: 0.85em;">
# 1. フィルタパイプライン適用
filtered_frame = self.spatial.process(depth_frame)
filtered_frame = self.temporal.process(filtered_frame)

# 4. 中央値を計算 (ベースライン用)
median_depth = float(np.median(valid_depth)) * 0.001

# 5. EMAでベースライン更新
self.baseline = (1.0 - alpha) * self.baseline + alpha * median_depth

# 6. 下位パーセンタイルで障害物検知
close_depth = float(np.percentile(valid_depth, 20.0)) * 0.001
        </code>
                </div>
            </section>
            <!-- Gen1 Content End -->
        </div>

        <div id="gen2" class="tab-content">
            <!-- Gen2 Content Start -->
            <section>
                <h2>Gen 2: 1. 技術的実装詳細 (Academic)</h2>
                <p>本セクションでは、<code>backend/height_detector.py</code> で使用される数理モデルと処理パイプラインの詳細について記述します。本システムは、完全な3次元点群（3D
                    Point Cloud）再構成およびSVDに基づく平面フィッティングを採用し、Intel RealSense Viewerと同等の計測精度を実現しています。</p>

                <h3>1.1 3次元点群復元 (Deprojection)</h3>
                <p>生の深度マップを直接処理する代わりに、システムはまず有効な各ピクセル $(u, v)$ とその深度 $d_{\text{raw}}$ を、カメラ座標系の3次元点 $\mathbf{P} = [X, Y,
                    Z]^T$ に変換します。</p>

                <div class="math-block">
                    $$
                    \begin{aligned}
                    Z &= d_{\text{raw}} \times s \\
                    X &= \frac{(u - c_x) \times Z}{f_x} \\
                    Y &= \frac{(v - c_y) \times Z}{f_y}
                    \end{aligned}
                    $$
                </div>

                <p>ここで：</p>
                <ul>
                    <li>$s$: 深度スケール単位（通常はミリメートル単位のため0.001）</li>
                    <li>$(c_x, c_y)$: 内部パラメータによる主点座標（光学中心）</li>
                    <li>$(f_x, f_y)$: 内部パラメータによる焦点距離</li>
                </ul>
                <p>このベクトル化計算は、Region of Interest (ROI) 内の全画素に対してNumPyを用いて行われ、形状 $(N, 3)$ の点群テンソルが生成されます。</p>

                <h3>1.2 SVDによる床平面推定</h3>
                <p>ロバストなゼロ基準を確立するために、システムはROI内の点群データから床平面の方程式 $ax + by + cz + d = 0$ を推定します。</p>
                <p>我々は、<strong>特異値分解（SVD）</strong>を用いて全最小二乗問題を解くことでこれを実現しています：</p>

                <h3>1. System Overview (System Workflow)</h3>
                <div class="mermaid">
                    flowchart TD
                    A["RealSense デプスセンサ"] -->|"生の深度画像"| B["3次元点群生成"]
                    B -->|"ROI内の点群 (Nx3)"| C{"床面キャリブレーション済み?"}
                    C -->|No| D["床高さ = 0mm に設定"]
                    C -->|Yes| E["点-平面間距離計算"]
                    E --> F["高さ = 平面からの最大距離"]
                    F --> G["障害物検知"]
                </div>

                <ol>
                    <li><strong>重心計算</strong>: 全点 $P_i$ の幾何学的中心 $\mathbf{\bar{p}}$ を計算します。
                        $$ \mathbf{\bar{p}} = \frac{1}{N} \sum_{i=1}^{N} P_i $$
                    </li>
                    <li><strong>中心化 (Centering)</strong>: すべての点を原点中心に移動させます。
                        $$ P'_{\text{centered}} = P - \mathbf{\bar{p}} $$
                    </li>
                    <li><strong>SVD分解</strong>: 中心化された行列を分解します。
                        $$ P'_{\text{centered}} = U \Sigma V^T $$
                    </li>
                    <li><strong>法線抽出</strong>: 最小特異値に関連付けられた特異ベクトル（$V^T$の最後の行、または$V$の最後の列）が、平面の法線ベクトル $\mathbf{n} = [a,
                        b, c]^T$ となります。
                        $$ \mathbf{n} = V^T[-1] $$
                    </li>
                    <li><strong>平面パラメータ $d$</strong>: 平面が重心を通るという制約から導出されます。
                        $$ d = - \mathbf{n} \cdot \mathbf{\bar{p}} $$
                    </li>
                </ol>

                <div class="note">
                    <strong>コード参照:</strong> <code>backend/height_detector.py</code> 内の
                    <code>HeightDetector._fit_floor_plane()</code>
                    を参照してください。法線ベクトルは、一貫した距離符号を保証するために、常にカメラ方向（負のZ方向）を向くように強制されています。
                </div>

                <h3>1.3 障害物高さ計算</h3>
                <p>障害物検知のために、システムはROI内の各点 $P_i$ から推定された床平面までの「符号付き垂直距離」$h_i$ を計算します。</p>

                <div class="math-block">
                    $$ h_i = a X_i + b Y_i + c Z_i + d $$
                </div>

                <p>平面の法線 $\mathbf{n}$ がカメラ方向を向いているため、床より「上」にある点（障害物）は正の距離値を持ちます。</p>

                <h4>ロバストな最大値推定</h4>
                <p>単一ピクセルのノイズによる最大高さのスパイク（異常値）を防ぐため、以下の処理を行います：</p>
                <ol>
                    <li>全ての距離 $h_i$ を降順にソートします。</li>
                    <li>上位 $N$ 点（通常 $N=20$）の算術平均をとります。</li>
                </ol>

                <div class="math-block">
                    $$ H_{\text{final}} = \frac{1}{N} \sum_{j=1}^{N} h_{(j)} $$
                </div>

                <h3>1.4 ポストプロセス (EMA平滑化)</h3>
                <p>最終的な出力は、ジッター（微細な揺れ）を低減するために指数移動平均（EMA）を用いて平滑化されます：</p>
                <div class="math-block">
                    $$ H_t = (1 - \alpha) H_{t-1} + \alpha H_{\text{measured}} $$
                </div>
                <p>ここで、平滑化係数 $\alpha = 0.3$ が使用されています。</p>
            </section>
            <!-- Gen2 Content End -->
        </div>

        <footer>
            &copy; 2025 ServoDrive - RealSense Road Scanner Project
        </footer>
    </div>
</body>

</html>